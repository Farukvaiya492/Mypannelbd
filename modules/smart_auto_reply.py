import os
import asyncio
import logging
import re
import html
from collections import deque
from pyrogram import filters
from pyrogram.types import Message
from pyrogram.enums import ChatAction, UserStatus, ChatType
from .base_module import BaseModule


class SmartAutoReplyModule(BaseModule):
    def __init__(self, client, socketio):
        super().__init__(client, socketio)
        self.pending_replies = {}
        self.conversation_mode = {}

        if os.getenv('GEMINI_API_KEY', 'AIzaSyAy2uhi_G8A2ZZ7gPFXUjJOqQzJkvKRaqU'):
            self.auto_reply_message = "ğ‘° ğ’ğ’‚ğ’šğ’ƒğ’† ğ’ƒğ’–ğ’”ğ’š ğ’ğ’ğ’˜. ğŸ’\n\nğŸ’¬ à¦†à¦ªà¦¨à¦¿ à¦šà¦¾à¦‡à¦²à§‡ à¦†à¦®à¦¾à¦•à§‡ à¦•à¦¿à¦›à§ à¦œà¦¿à¦œà§à¦à¦¾à¦¸à¦¾ à¦•à¦°à¦¤à§‡ à¦ªà¦¾à¦°à§‡à¦¨, à¦†à¦®à¦¿ AI à¦¦à¦¿à¦¯à¦¼à§‡ à¦‰à¦¤à§à¦¤à¦° à¦¦à§‡à¦“à¦¯à¦¼à¦¾à¦° à¦šà§‡à¦·à§à¦Ÿà¦¾ à¦•à¦°à¦¬à¥¤ \n ğŸ’ ğ‘»ğ’‰ğ’‚ğ’ğ’Œ ğ‘¼ ğŸ’"
        else:
            self.auto_reply_message = "ğ‘° ğ’ğ’‚ğ’šğ’ƒğ’† ğ’ƒğ’–ğ’”ğ’š ğ’ğ’ğ’˜. ğŸ’\n\nâš ï¸ Note: AI features are currently disabled (GEMINI_API_KEY not configured).\n\n ğŸ’ ğ‘»ğ’‰ğ’‚ğ’ğ’Œ ğ‘¼ ğŸ’"

        self.programmatic_message_count = 0
        self._programmatic_lock = asyncio.Lock()

        self.reply_timeout = 30  
        self.group_reply_timeout = 30
        self.conversation_history = {}  
        self.max_history_length = 50
        self.pending_group_replies = {}

        self.api_key = os.getenv('GEMINI_API_KEY' , 'AIzaSyAP157_yKytJMfYSTUwAKMwUgmVNouGKEY')
        if not self.api_key:
            logging.error("âŒ GEMINI_API_KEY environment variable not set! AI features will not work.")
            self.api_url = None
        else:
            self.api_url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key={self.api_key}"

        # Code formatting configuration
        self.supported_languages = {
            'python': 'python', 'py': 'python',
            'javascript': 'javascript', 'js': 'javascript',
            'java': 'java',
            'cpp': 'cpp', 'c++': 'cpp',
            'c': 'c',
            'html': 'html',
            'css': 'css',
            'php': 'php',
            'sql': 'sql',
            'json': 'json',
            'xml': 'xml',
            'bash': 'bash', 'shell': 'bash',
            'markdown': 'markdown', 'md': 'markdown',
            'yaml': 'yaml', 'yml': 'yaml'
        }

        if self.api_key:
            logging.info("âœ… Using Gemini API key from environment variables")

    def setup(self):
        """Register message handlers for smart auto-reply functionality."""

        @self.client.on_message(filters.private & filters.command("clear") & filters.incoming)
        async def handle_clear_command(client, message: Message):
            """Clear conversation history for this chat."""
            chat_id = message.chat.id
            if chat_id in self.conversation_history:
                self.conversation_history[chat_id].clear()
                await message.reply_text("âœ… **Conversation history cleared!**\n\nà¦¨à¦¤à§à¦¨ à¦•à¦¥à§‹à¦ªà¦•à¦¥à¦¨ à¦¶à§à¦°à§ à¦¹à¦¬à§‡ à¦à¦–à¦¨ à¦¥à§‡à¦•à§‡à¥¤ ğŸ”„")
                logging.info(f"ğŸ—‘ï¸ Conversation history cleared for {message.from_user.first_name}")
                self.emit_terminal(f'ğŸ—‘ï¸ History cleared for {message.from_user.first_name}')
            else:
                await message.reply_text("â„¹ï¸ à¦•à§‹à¦¨ conversation history à¦¨à§‡à¦‡ à¦à¦‡ chat à¦à¥¤")

        @self.client.on_message(filters.private & filters.command("stop") & filters.outgoing)
        async def handle_stop_command(client, message: Message):
            """Stop all conversation modes and pending replies."""
            self.conversation_mode.clear()
            self.pending_replies.clear()
            logging.info("ğŸ›‘ All conversation modes stopped")
            self.emit_terminal("ğŸ›‘ Conversation modes stopped")
            await message.edit_text("ğŸ›‘ **Auto-reply Stopped**\n\nà¦¸à¦¬ conversation mode à¦¬à¦¨à§à¦§ à¦•à¦°à¦¾ à¦¹à¦¯à¦¼à§‡à¦›à§‡à¥¤")

        @self.client.on_message(filters.group & filters.text & filters.incoming & filters.mentioned)
        async def handle_group_mention(client, message: Message):
            """Handle mentions in groups - wait 3 minutes before auto-reply."""
            try:
                user = message.from_user
                chat_id = message.chat.id
                msg_id = message.id
                group_name = message.chat.title or "Group"

                logging.info(f"ğŸ‘¥ Mentioned in group '{group_name}' by {user.first_name}")
                self.emit_terminal(f'ğŸ‘¥ Mentioned in {group_name} by {user.first_name}')

                group_key = f"{chat_id}_{msg_id}"

                if group_key in self.pending_group_replies:
                    return

                logging.info(f"ğŸ“¨ New group mention from {user.first_name} - Waiting {self.group_reply_timeout}s for reply")
                self.emit_terminal(f'â° Group mention: Waiting {self.group_reply_timeout}s...')

                async def send_delayed_group_reply():
                    try:
                        logging.info(f"â° Waiting {self.group_reply_timeout} seconds before group auto-reply...")
                        await asyncio.sleep(self.group_reply_timeout)

                        if group_key not in self.pending_group_replies:
                            logging.info("âŒ Group reply was cancelled")
                            return

                        logging.info(f"ğŸ“¤ Sending auto-reply to group '{group_name}'...")
                        self.emit_terminal(f'ğŸ“¤ Auto-replying in {group_name}')

                        busy_message = "ğ‘° ğ’ğ’‚ğ’šğ’ƒğ’† ğ’ƒğ’–ğ’”ğ’š ğ’ğ’ğ’˜. ğŸ’\n\n ğŸ’¬ à¦•à§‹à¦¨ à¦¦à¦°à¦•à¦¾à¦° à¦¹à¦²à§‡ â„‘ğ”«ğ”Ÿğ”¬ğ”µ ğ”ªğ”¢. ğŸ’ ğ‘»ğ’‰ğ’‚ğ’ğ’Œ ğ‘¼ ğŸ’"

                        async with self._programmatic_lock:
                            self.programmatic_message_count += 1

                        try:
                            await message.reply_text(busy_message)
                            logging.info(f"âœ… Sent busy message to group '{group_name}'")
                            self.emit_terminal(f'âœ… Replied in group: {group_name}')
                        finally:
                            async with self._programmatic_lock:
                                self.programmatic_message_count -= 1

                    except asyncio.CancelledError:
                        logging.info("âŒ Group auto-reply cancelled by user response")
                        self.emit_terminal(f'âŒ Group auto-reply cancelled')
                    except Exception as e:
                        logging.error(f"Error sending group auto-reply: {e}", exc_info=True)
                    finally:
                        if group_key in self.pending_group_replies:
                            del self.pending_group_replies[group_key]

                task = asyncio.create_task(send_delayed_group_reply())
                self.pending_group_replies[group_key] = task

            except Exception as e:
                logging.error(f"Error handling group mention: {e}", exc_info=True)

        @self.client.on_message(filters.group & filters.outgoing)
        async def handle_group_outgoing(client, message: Message):
            """Cancel pending group auto-replies when user manually replies in group."""
            try:
                async with self._programmatic_lock:
                    if self.programmatic_message_count > 0:
                        return

                chat_id = message.chat.id

                cancelled_count = 0
                keys_to_remove = []

                for key, task in self.pending_group_replies.items():
                    if key.startswith(f"{chat_id}_"):
                        task.cancel()
                        keys_to_remove.append(key)
                        cancelled_count += 1

                for key in keys_to_remove:
                    del self.pending_group_replies[key]

                if cancelled_count > 0:
                    group_name = message.chat.title or "Group"
                    logging.info(f"âœ… Cancelled {cancelled_count} pending group auto-reply(s) in '{group_name}'")
                    self.emit_terminal(f'âœ… Cancelled group auto-reply in {group_name}')

            except Exception as e:
                logging.error(f"Error handling group outgoing: {e}", exc_info=True)

        @self.client.on_message(filters.private & filters.text & filters.incoming)
        async def handle_incoming_message(client, message: Message):
            """
            Handle incoming messages with smart auto-reply logic.
            Checks your online/offline status automatically.
            """
            chat_id = message.chat.id
            msg_id = message.id
            user = message.from_user

            if message.text.startswith('/gem'):
                return

            if message.text.startswith('/'):
                logging.info(f"â­ï¸ Skipping auto-reply for command: {message.text}")
                self.emit_terminal(f'âš™ï¸ Command from {user.first_name}: "{message.text}"')
                return

            logging.info(f'ğŸ“¨ Message from {user.first_name}: "{message.text[:50]}..."')
            self.emit_terminal(f'ğŸ“¨ Message from {user.first_name}: "{message.text[:50]}..."')

            if chat_id in self.conversation_mode:
                if not self.api_key:
                    logging.warning(f"âš ï¸ Conversation mode active but GEMINI_API_KEY not set - deactivating")
                    self.emit_terminal(f'âš ï¸ AI unavailable for {user.first_name}')
                    del self.conversation_mode[chat_id]

                    async with self._programmatic_lock:
                        self.programmatic_message_count += 1
                    try:
                        await message.reply_text("âš ï¸ AI features are currently unavailable. GEMINI_API_KEY environment variable is not configured.\n\nPlease set the API key to enable AI responses.")
                    finally:
                        async with self._programmatic_lock:
                            self.programmatic_message_count -= 1
                    return

                logging.info(f"ğŸ’¬ Conversation mode active for {user.first_name} - Instant AI response")
                self.emit_terminal(f'ğŸ’¬ AI responding to {user.first_name}')

                await client.send_chat_action(message.chat.id, ChatAction.TYPING)

                try:
                    response = await self._call_gemini_api(message.text, chat_id)

                    async with self._programmatic_lock:
                        self.programmatic_message_count += 1

                    try:
                        # Format the response for Telegram with proper code formatting
                        formatted_response = self._format_response_for_telegram(response)
                        await message.reply_text(formatted_response, parse_mode='HTML')
                        logging.info(f"âœ… AI responded to {user.first_name} in conversation mode")
                        self.emit_terminal(f'âœ… AI replied to {user.first_name}')
                    finally:
                        async with self._programmatic_lock:
                            self.programmatic_message_count -= 1

                except Exception as e:
                    logging.error(f"AI response error: {e}")

                    async with self._programmatic_lock:
                        self.programmatic_message_count += 1

                    try:
                        await message.reply_text("âŒ à¦¦à§à¦ƒà¦–à¦¿à¦¤, AI à¦‰à¦¤à§à¦¤à¦° à¦¦à¦¿à¦¤à§‡ à¦ªà¦¾à¦°à§‡à¦¨à¦¿à¥¤ `/gem` command à¦¬à§à¦¯à¦¬à¦¹à¦¾à¦° à¦•à¦°à§‡ à¦šà§‡à¦·à§à¦Ÿà¦¾ à¦•à¦°à§à¦¨à¥¤")
                    finally:
                        async with self._programmatic_lock:
                            self.programmatic_message_count -= 1

                return

            logging.info(f"ğŸ“¨ New message from {user.first_name} - Waiting {self.reply_timeout}s for reply")
            self.emit_terminal(f'â° Waiting 1 min for reply to {user.first_name}')

            self.pending_replies[chat_id] = {
                'message_id': msg_id,
                'timestamp': asyncio.get_event_loop().time()
            }

            asyncio.create_task(self._schedule_auto_reply(message, chat_id, msg_id))

        @self.client.on_message(filters.private & filters.text & filters.outgoing)
        async def handle_outgoing_message(client, message: Message):
            chat_id = message.chat.id

            if self.programmatic_message_count > 0:
                logging.info(f"ğŸ¤– Programmatic message sent - Idle timer NOT reset")
                return

            logging.info(f"ğŸ‘¤ You replied manually to chat {chat_id}")
            self.emit_terminal(f'ğŸ‘¤ Manual reply sent')

            if chat_id in self.pending_replies:
                logging.info(f"âœ… Cancelling auto-reply (manual reply sent)")
                self.emit_terminal(f'âœ… Auto-reply cancelled')
                del self.pending_replies[chat_id]

            if chat_id in self.conversation_mode:
                logging.info(f"ğŸ”´ Manual reply - Conversation mode deactivated")
                self.emit_terminal(f'ğŸ”´ Conversation mode OFF')
                del self.conversation_mode[chat_id]

    def _format_response_for_telegram(self, text: str) -> str:
        """
        Format Gemini API response for Telegram with proper code formatting.
        Converts markdown code blocks to Telegram-friendly HTML formatting.
        """
        try:
            # Escape HTML characters first
            text = html.escape(text)

            # Handle code blocks with language specification
            code_block_pattern = r'```(\w+)?\s*(.*?)```'

            def replace_code_block(match):
                language = match.group(1) or 'text'
                code_content = match.group(2).strip()

                # Map language to proper name
                lang_display = self.supported_languages.get(language.lower(), language)

                # Format for Telegram with monospace and language label
                formatted_code = f'<b>â”Œâ”€â”€â”€ {lang_display.upper()} â”€â”€â”€â”</b>\n'
                formatted_code += f'<code>{code_content}</code>\n'
                formatted_code += f'<b>â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜</b>'

                return formatted_code

            # Replace code blocks
            formatted_text = re.sub(code_block_pattern, replace_code_block, text, flags=re.DOTALL)

            # Handle inline code with backticks
            inline_code_pattern = r'`([^`]+)`'
            formatted_text = re.sub(inline_code_pattern, r'<code>\1</code>', formatted_text)

            # Handle bold text (convert **text** to <b>text</b>)
            bold_pattern = r'\*\*(.*?)\*\*'
            formatted_text = re.sub(bold_pattern, r'<b>\1</b>', formatted_text)

            # Handle italic text (convert *text* to <i>text</i>)
            italic_pattern = r'\*(.*?)\*'
            formatted_text = re.sub(italic_pattern, r'<i>\1</i>', formatted_text)

            # Preserve line breaks
            formatted_text = formatted_text.replace('\n', '<br>')

            return formatted_text

        except Exception as e:
            logging.error(f"Error formatting response: {e}")
            return text  # Return original text if formatting fails

    async def _schedule_auto_reply(self, message: Message, chat_id: int, msg_id: int):
        try:
            logging.info(f"â° Waiting {self.reply_timeout} seconds before auto-reply...")
            await asyncio.sleep(self.reply_timeout)

            if chat_id in self.pending_replies and self.pending_replies[chat_id]['message_id'] == msg_id:
                try:
                    logging.info(f"ğŸ“¤ Sending auto-reply to {message.from_user.first_name}...")

                    async with self._programmatic_lock:
                        self.programmatic_message_count += 1

                    try:
                        await self.client.send_message(chat_id, self.auto_reply_message)

                        if self.api_key:
                            self.conversation_mode[chat_id] = True
                            logging.info(f'âœ… Auto-reply sent + Conversation mode ACTIVATED for {message.from_user.first_name}')
                            self.emit_terminal(f'ğŸ¤– Auto-replied + ğŸ’¬ Conversation mode ON for {message.from_user.first_name}')
                        else:
                            logging.info(f'âœ… Auto-reply sent (AI disabled - no GEMINI_API_KEY) for {message.from_user.first_name}')
                            self.emit_terminal(f'ğŸ¤– Auto-replied to {message.from_user.first_name} (AI disabled)')

                        self.away_message_used = True

                        del self.pending_replies[chat_id]
                    finally:
                        async with self._programmatic_lock:
                            self.programmatic_message_count -= 1

                except Exception as e:
                    logging.error(f"âŒ Failed to send auto-reply: {e}", exc_info=True)
                    self.emit_terminal(f'âŒ Auto-reply failed: {str(e)}')

        except Exception as e:
            logging.error(f"Error in auto-reply scheduling: {e}", exc_info=True)

    async def _call_gemini_api(self, query: str, chat_id: int) -> str:
        import requests

        if not self.api_url:
            logging.error("âŒ Cannot call Gemini API: GEMINI_API_KEY not configured")
            raise Exception("Gemini API key not configured. Please set GEMINI_API_KEY environment variable.")

        if chat_id not in self.conversation_history:
            self.conversation_history[chat_id] = deque(maxlen=self.max_history_length)

            system_prompt = {
                "role": "user",
                "parts": [{
                    "text": "You are a helpful AI assistant of Mahit Labib. Language guidelines:\n"
                            "- If the user writes in Bengali (à¦¬à¦¾à¦‚à¦²à¦¾) or uses English letters to write Bengali (Banglish/Roman Bengali), respond in Bengali (à¦¬à¦¾à¦‚à¦²à¦¾ script)\n"
                            "- If the user writes in English, respond in English\n"
                            "- If the user writes in any other language, respond in English\n"
                            "- Be natural, friendly, and helpful in your responses\n"
                            "- When providing code, use proper markdown formatting with language specification\n"
                            "- Format code blocks with triple backticks and language name\n"
                            "- For inline code, use single backticks\n"
                            "- Use **bold** for emphasis and *italic* for subtle emphasis"
                }]
            }
            model_ack = {
                "role": "model",
                "parts": [{"text": "à¦†à¦®à¦¿ à¦¬à§à¦à§‡à¦›à¦¿! à¦†à¦®à¦¿ à¦¬à¦¾à¦‚à¦²à¦¾ à¦¬à¦¾ à¦‡à¦‚à¦°à§‡à¦œà¦¿à¦¤à§‡ à¦¸à¦¾à¦¹à¦¾à¦¯à§à¦¯ à¦•à¦°à¦¤à§‡ à¦ªà¦¾à¦°à¦¿à¥¤ à¦•à§‹à¦¡ à¦¸à¦¹ à¦‰à¦¤à§à¦¤à¦° à¦¦à§‡à¦¬à¦¾à¦° à¦¸à¦®à¦¯à¦¼ à¦†à¦®à¦¿ à¦¸à¦ à¦¿à¦• à¦®à¦¾à¦°à§à¦•à¦¡à¦¾à¦‰à¦¨ à¦«à¦°à¦®à§à¦¯à¦¾à¦Ÿ à¦¬à§à¦¯à¦¬à¦¹à¦¾à¦° à¦•à¦°à¦¬à¥¤ à¦•à¦¿à¦­à¦¾à¦¬à§‡ à¦¸à¦¾à¦¹à¦¾à¦¯à§à¦¯ à¦•à¦°à¦¤à§‡ à¦ªà¦¾à¦°à¦¿?"}]
            }
            self.conversation_history[chat_id].append(system_prompt)
            self.conversation_history[chat_id].append(model_ack)

        user_message = {
            "role": "user",
            "parts": [{"text": query}]
        }
        self.conversation_history[chat_id].append(user_message)

        payload = {
            "contents": list(self.conversation_history[chat_id]),
            "generationConfig": {
                "temperature": 0.7,
                "topK": 40,
                "topP": 0.95,
                "maxOutputTokens": 2048,
            }
        }

        headers = {
            "Content-Type": "application/json"
        }

        try:
            response = requests.post(
                self.api_url,
                json=payload,
                headers=headers,
                timeout=30
            )

            response.raise_for_status()
            data = response.json()

            if 'candidates' in data and len(data['candidates']) > 0:
                candidate = data['candidates'][0]
                if 'content' in candidate and 'parts' in candidate['content']:
                    parts = candidate['content']['parts']
                    if len(parts) > 0 and 'text' in parts[0]:
                        ai_response = parts[0]['text']

                        model_message = {
                            "role": "model",
                            "parts": [{"text": ai_response}]
                        }
                        self.conversation_history[chat_id].append(model_message)

                        return ai_response

            return "âŒ à¦¦à§à¦ƒà¦–à¦¿à¦¤, AI à¦¥à§‡à¦•à§‡ à¦¸à¦ à¦¿à¦• à¦‰à¦¤à§à¦¤à¦° à¦ªà¦¾à¦“à¦¯à¦¼à¦¾ à¦¯à¦¾à¦¯à¦¼à¦¨à¦¿à¥¤"

        except Exception as e:
            logging.error(f"Gemini API error: {e}", exc_info=True)
            raise

    def cleanup(self):
        """Clean up resources."""
        self.pending_replies.clear()
        self.conversation_mode.clear()
        self.conversation_history.clear()
        logging.info("Smart Auto-Reply module cleaned up")